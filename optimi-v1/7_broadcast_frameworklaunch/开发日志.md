# 7_broadcast_frameworklaunch 开发日志

## Round 1
- 本轮优化方向：
  - 在不改 install/run 链路的前提下，补全 broadcast 的安全分片能力与调用侧参数正确性。
- 代码改动：
  - `BroadcastCustom/op_host/broadcast_custom.cpp`
    - 增加 `dim/axis/num/shape` 合法性校验。
    - 引入 `tilenum` 自适应（`dim=1` 或 `axis=1` 时最多 4 分片，且保证整除）。
  - `BroadcastCustom/op_kernel/broadcast_custom.cpp`
    - 补充按 block 的长度与偏移计算（处理非整除场景）。
    - `tilenum` 非法或不可整除时回退为 1，防止错误切片。
    - 输出 GM 缓冲长度从 `blockLength` 修正为 `blockLength * num`。
  - `AclNNInvocationNaive/main.cpp`
    - 修复 `dim` 传参错误：由 `inputXHostData.size()` 改为 `inputXShape.size()`。
- 逻辑初验与输入模拟推理：
  - 用本机 Python 推导 `tilenum` 选择与 block 切分偏移，验证总覆盖长度守恒。
  - 对 `axis=1` 的样例（`[16,1] -> [16,3]`）验证 `tilenum=1` 路径保持兼容。
- 结论：
  - 本轮先稳住 correctness 与可分片基础，后续 round 再推进更激进的并行策略。

## Round 2
- 本轮优化方向：
  - 减少 kernel 循环内临时缓冲管理开销（`tmpQueue.Get/Free`）。
- 代码改动：
  - `BroadcastCustom/op_kernel/broadcast_custom.cpp`
    - `Process()` 中在循环外一次性获取 `tmpTensor`（仅 `tmpSize != 0` 时）。
    - `Compute()` 新签名接收 `hasTmp + tmpTensor`，循环内复用同一临时缓冲。
    - 循环结束后统一释放 `tmpTensor`。
- 逻辑初验与输入模拟推理：
  - 检查 `Compute` 调用与定义已一致，`hasTmp=false` 路径保持原语义。
  - `hasTmp=true` 时临时缓冲生命周期覆盖整个 loop，避免每 tile 重复申请释放。
- 结论：
  - 功能不变，内层循环管理开销下降，为后续更大 shape 的广播场景留出余量。

## Round 3
- 本轮优化方向：
  - 修复多 dtype 场景下的元素字节数映射错误。
- 代码改动：
  - `BroadcastCustom/op_host/broadcast_custom.cpp`
    - `dtypesize` 计算改为：
      - `float16 -> 2`
      - `float -> 4`
      - `int8/uint8 -> 1`
    - 非支持 dtype 直接返回 `GRAPH_FAILED`。
- 逻辑初验与输入模拟推理：
  - `GetBroadCastMaxMinTmpSize` 的输入字节数现在与 dtype 真值一致，避免临时缓冲估算偏差。
  - 该变更不会影响 `float16` 既有路径。
- 结论：
  - broadcast 在 `int8/uint8` 路径下的 host 侧资源估算正确性补齐。
