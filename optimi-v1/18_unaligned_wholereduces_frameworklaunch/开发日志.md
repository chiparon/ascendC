# 18_unaligned_wholereduces_frameworklaunch 开发日志

## Round 1
- 本轮优化方向：
  - 将 WholeReduceSum 从单核整图处理改为“按行分核处理”，降低单核 UB 占用并提升并行度。
- 代码改动：
  - `WholeReduceSumCustom/op_host/whole_reduce_sum_custom.cpp`
    - `TilingFunc` 增加输入维度与零维检查。
    - `blockDim` 从固定 1 改为 `min(rows, coreNumAiv)`。
    - `InferShape` 明确输出为 `[rows, 1]`。
  - `WholeReduceSumCustom/op_kernel/whole_reduce_sum_custom.cpp`
    - 按 `blockIdx/blockNum` 计算 `rowOffset/rowCount`。
    - 每核仅拷贝并归约自己的行区间，不再复制全矩阵。
    - `rowCount==0` 时直接 idle 返回，避免空核访问。
    - `CopyIn/Compute/CopyOut` 全部改用 `rowCount`。
- 逻辑初验与输入模拟推理：
  - 用本机 Python 推演多组 `(rows, blocks)` 分配，验证：
    - 行覆盖完整
    - 无重复覆盖
    - 小 rows 大 blocks 场景可安全 idle
- 结论：
  - 完成了并行化基础改造，后续 round 可继续做非对齐访存与分层归约细化。

## Round 2
- 本轮优化方向：
  - host 并行度从“按行数拉满”改为“按工作量估算”，降低小 shape 过度并行开销。
- 代码改动：
  - `WholeReduceSumCustom/op_host/whole_reduce_sum_custom.cpp`
    - 新增 `targetElemsPerCore=4096` 估算策略：
      - `suggestedBlockDim = ceil(rows*cols / targetElemsPerCore)`
      - 再与 `rows/coreNum` 共同夹紧。
    - 新增 `WRS_FORCE_BLOCKDIM` 强制覆盖入口用于 A/B。
- 逻辑初验与输入模拟推理：
  - 本机 Python 验证：
    - 小 shape（`13x123`）默认 `blockDim=1`
    - 大 shape（`4096x1024`）可扩展到 `48`
    - 强制值受 `rows/coreNum` 上限保护
- 结论：
  - 并行策略更稳健，可减少小规模任务的调度损失，同时保留可控实验开关。

## Round 3
- 本轮优化方向：
  - 增加 `DataCopyExtParams` 行重复上限约束，防止极大 `rows` 场景参数溢出风险。
- 代码改动：
  - `WholeReduceSumCustom/op_host/whole_reduce_sum_custom.cpp`
    - 引入 `maxRowsPerCore=65535`。
    - 计算 `minBlockByRowBound = ceil(rows / 65535)`，并将 `blockDim` 下限提升到该值。
    - `WRS_FORCE_BLOCKDIM` 仍可强制覆盖，但不会突破行重复上限约束。
- 逻辑初验与输入模拟推理：
  - 本机 Python 验证：`rows=70000` 时 `blockDim` 自动不低于 2，满足每核行数上限。
  - 正常规模（如 `4096x1024`）不受影响。
- 结论：
  - 大 shape 可靠性进一步增强，避免隐藏参数越界问题进入 NPU 才暴露。
