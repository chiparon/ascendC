# 10_matmul_frameworklaunch 开发日志

## Round 1
- 本轮优化方向：
  - 打通默认调用链（`AclNNInvocation + MatmulCustomSingleCore`）的动态 shape 与多核执行入口，去掉关键硬编码。
- 代码改动：
  - `AclNNInvocation/src/main.cpp`
    - 新增 `MATMUL_M/N/K` 环境变量读取，算子描述改为动态 shape。
  - `AclNNInvocation/scripts/gen_data.py`
    - 输入/真值生成同步支持 `MATMUL_M/N/K`。
  - `MatmulCustomSingleCore/op_host/matmul_custom.cpp`
    - `blockDim` 改为基于 `tiling.cubeTilingData.usedCoreNum` 自适应设置。
  - `MatmulCustomSingleCore/op_kernel/matmul_custom.cpp`
    - 从固定 `GetBlockIdx() >= 1` 改为 `>= tiling.usedCoreNum`。
    - 增加 tail 处理（`SetTail`），并记录 `mIdx/nIdx` 做分块偏移。
- 逻辑初验与输入模拟推理：
  - `gen_data.py` 本机静态检查与小尺寸数据生成通过（`M=64,N=32,K=16` 文件尺寸符合预期）。
  - 用 Python 推演分块偏移/尾块覆盖，典型 shape 下 tile 覆盖与唯一性一致。
- 结论：
  - 默认链路具备了后续高维 shape 调优前提，且 kernel 不再被单核硬限制。

## Round 2
- 本轮优化方向：
  - host 侧 tiling 从固定 `baseM/baseN` 改为 shape 自适应，并保留强制覆盖入口用于 A/B。
- 代码改动：
  - `MatmulCustomSingleCore/op_host/matmul_custom.cpp`
    - `baseM` 默认策略：`M>=4096 -> 128`，否则 `256`。
    - `baseN` 默认策略：`N>=2048 -> 256`，否则 `128`。
    - 新增环境变量覆盖：`MATMUL_FORCE_BASE_M` / `MATMUL_FORCE_BASE_N`。
- 逻辑初验与输入模拟推理：
  - 本机 Python 校验多组 `(M,N)` 取值，默认/强制路径均符合预期映射。
  - 保持原有 API 与 tiling 流程不变，仅改变分块参数来源。
- 结论：
  - 已具备 shape 档位调参与强制对照能力，后续 NPU 侧可直接做单变量扫描。

## Round 3
- 本轮优化方向：
  - 统一 `MultiCore` 路径的 blockDim 计算口径，消除固定值带来的 shape 适配问题。
- 代码改动：
  - `MatmulCustomMultiCore/op_host/matmul_custom.cpp`
    - `310P`：`blockDim = usedCoreNum`
    - `910B`：`blockDim = (usedCoreNum + 1) / 2`
    - 删除固定 `blockDim=24`。
- 逻辑初验与输入模拟推理：
  - 本机推导 `usedCoreNum` 到 `blockDim` 的映射，验证在小核数与满核数场景均有界且单调。
  - 与 `12_matmulleakyrelu` 的设置口径保持一致。
- 结论：
  - `10_matmul` 的多核路径并行配置完成自适应化，便于后续跨 shape 稳定调优。
